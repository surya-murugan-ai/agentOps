#!/usr/bin/env python3
"""
Direct data upload using SQL for comprehensive testing
"""

import pandas as pd
import psycopg2
import os
from datetime import datetime, timedelta
import uuid
import json

def get_db_connection():
    """Get database connection"""
    return psycopg2.connect(os.environ['DATABASE_URL'])

def upload_metrics_data():
    """Upload metrics data directly to database"""
    
    # Read one metrics file for testing
    df = pd.read_excel('attached_assets/metrics_2025-08-15_1755250222160.xlsx')
    print(f"Processing {len(df)} metrics records")
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    # Get existing server IDs
    cur.execute("SELECT id FROM servers LIMIT 10")
    server_ids = [row[0] for row in cur.fetchall()]
    print(f"Found {len(server_ids)} servers: {server_ids}")
    
    if not server_ids:
        print("No servers found - uploading failed")
        return 0
    
    inserted_count = 0
    
    # Process metrics data in smaller batches
    for i, row in df.iterrows():
        if i >= 500:  # Limit to first 500 records for testing
            break
            
        try:
            # Use rotating server IDs
            server_id = server_ids[i % len(server_ids)]
            
            # Clean and validate data
            cpu_usage = float(row.get('cpu_usage', 0)) if pd.notna(row.get('cpu_usage')) else 0
            memory_usage = float(row.get('memory_usage', 0)) if pd.notna(row.get('memory_usage')) else 0
            disk_usage = float(row.get('disk_usage', 50)) if pd.notna(row.get('disk_usage')) else 50
            
            # Ensure values are valid
            cpu_usage = max(0, min(100, cpu_usage))
            memory_usage = max(0, min(100, memory_usage))
            disk_usage = max(0, min(100, disk_usage))
            
            # Create timestamp with some variation
            timestamp = datetime.now() - timedelta(minutes=i*5)
            
            # Insert metric record
            cur.execute("""
                INSERT INTO server_metrics 
                (id, server_id, cpu_usage, memory_usage, memory_total, disk_usage, disk_total, 
                 network_latency, network_throughput, process_count, timestamp)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                str(uuid.uuid4()),
                server_id, 
                str(cpu_usage),
                str(memory_usage),
                16384,  # 16GB
                str(disk_usage),
                500,    # 500GB
                10.0 + (i % 50),  # Network latency
                100.0 + (i % 200), # Network throughput
                50 + (i % 100),    # Process count
                timestamp
            ))
            
            inserted_count += 1
            
            if inserted_count % 50 == 0:
                print(f"Inserted {inserted_count} metrics...")
                conn.commit()
                
        except Exception as e:
            print(f"Error inserting metric {i}: {e}")
            continue
    
    conn.commit()
    cur.close()
    conn.close()
    
    print(f"âœ… Successfully inserted {inserted_count} metrics")
    return inserted_count

def trigger_agent_processing():
    """Wait for agents to process the new data"""
    print("â³ Waiting 60 seconds for agent processing...")
    import time
    time.sleep(60)

def test_system_outputs():
    """Test all system outputs after agent processing"""
    import requests
    
    BASE_URL = "http://localhost:5000"
    
    print("\nğŸ” Testing System Outputs:")
    print("=" * 50)
    
    endpoints = [
        ("/api/servers", "Servers"),
        ("/api/alerts", "Alerts"), 
        ("/api/anomalies", "Anomalies"),
        ("/api/predictions", "Predictions"),
        ("/api/remediation-actions", "Remediation Actions"),
        ("/api/audit-logs", "Audit Logs"),
        ("/api/dashboard/metrics", "Dashboard Metrics")
    ]
    
    test_results = {}
    
    for endpoint, name in endpoints:
        try:
            response = requests.get(f"{BASE_URL}{endpoint}")
            if response.status_code == 200:
                data = response.json()
                
                if isinstance(data, list):
                    count = len(data)
                    test_results[name] = {"count": count, "status": "success"}
                    print(f"âœ… {name}: {count} records")
                    
                    if count > 0 and len(data) > 0:
                        # Show sample data
                        sample = data[0] if isinstance(data[0], dict) else {}
                        key_fields = list(sample.keys())[:3] if sample else []
                        print(f"   Sample fields: {key_fields}")
                        
                elif isinstance(data, dict):
                    test_results[name] = {"data": data, "status": "success"}  
                    print(f"âœ… {name}: {data}")
                else:
                    test_results[name] = {"status": "unknown_format"}
                    print(f"âš ï¸  {name}: Unknown data format")
                    
            else:
                test_results[name] = {"status": "error", "code": response.status_code}
                print(f"âŒ {name}: HTTP {response.status_code}")
                
        except Exception as e:
            test_results[name] = {"status": "exception", "error": str(e)}
            print(f"âŒ {name}: {e}")
    
    return test_results

def test_agent_details():
    """Test individual agent processing details"""
    import requests
    
    BASE_URL = "http://localhost:5000"
    
    agents = [
        ("telemetry-collector-001", "Telemetry Collector"),
        ("anomaly-detector-001", "Anomaly Detector"), 
        ("predictive-analytics-001", "Predictive Analytics"),
        ("recommendation-engine-001", "Recommendation Engine"),
        ("approval-compliance-001", "Approval & Compliance"),
        ("remediation-executor-001", "Remediation Executor"),
        ("audit-reporting-001", "Audit & Reporting")
    ]
    
    print("\nğŸ¤– Testing Agent Processing:")
    print("=" * 50)
    
    for agent_id, agent_name in agents:
        try:
            response = requests.get(f"{BASE_URL}/api/agents/{agent_id}/details")
            if response.status_code == 200:
                data = response.json()
                agent = data['agent']
                activities = data['recentActivities']
                
                print(f"\nğŸ” {agent_name}:")
                print(f"   Status: {agent['status']}")
                print(f"   Processed Count: {agent.get('processedCount', 0)}")
                print(f"   Error Count: {agent.get('errorCount', 0)}")
                print(f"   Recent Activities: {len(activities.get('auditLogs', []))}")
                
                # Show latest activity if available
                audit_logs = activities.get('auditLogs', [])
                if audit_logs:
                    latest = audit_logs[0]
                    print(f"   Latest Activity: {latest.get('action', 'N/A')}")
                    print(f"   Details: {latest.get('details', 'N/A')[:100]}...")
                    print(f"   âœ… Agent actively processing")
                else:
                    print(f"   âš ï¸  No recent processing activity")
                    
        except Exception as e:
            print(f"âŒ Error testing {agent_name}: {e}")

def run_comprehensive_test():
    """Run complete end-to-end test"""
    
    print("ğŸš€ COMPREHENSIVE END-TO-END TESTING")
    print("=" * 60)
    print("Testing all AgentOps AI agents with real data")
    print("=" * 60)
    
    # Step 1: Upload metrics data
    print("\nğŸ“Š Step 1: Uploading Metrics Data")
    metrics_count = upload_metrics_data()
    
    if metrics_count > 0:
        # Step 2: Wait for processing
        trigger_agent_processing()
        
        # Step 3: Test outputs
        test_results = test_system_outputs()
        
        # Step 4: Test agents
        test_agent_details()
        
        # Step 5: Generate report
        print("\nğŸ“‹ COMPREHENSIVE TEST REPORT")
        print("=" * 60)
        
        successful_outputs = sum(1 for result in test_results.values() if result.get('status') == 'success')
        total_outputs = len(test_results)
        
        print(f"âœ… Data Upload: {metrics_count} metrics uploaded successfully")
        print(f"âœ… System Outputs: {successful_outputs}/{total_outputs} endpoints working")
        print(f"âœ… Agent Processing: All 7 agents tested")
        
        # Show key metrics
        if 'Servers' in test_results:
            server_count = test_results['Servers'].get('count', 0)
            print(f"ğŸ“Š Servers: {server_count}")
            
        if 'Alerts' in test_results:
            alert_count = test_results['Alerts'].get('count', 0)
            print(f"ğŸš¨ Alerts Generated: {alert_count}")
            
        if 'Anomalies' in test_results:
            anomaly_count = test_results['Anomalies'].get('count', 0)
            print(f"ğŸ” Anomalies Detected: {anomaly_count}")
            
        if 'Predictions' in test_results:
            prediction_count = test_results['Predictions'].get('count', 0)
            print(f"ğŸ”® Predictions Created: {prediction_count}")
            
        if 'Remediation Actions' in test_results:
            remediation_count = test_results['Remediation Actions'].get('count', 0)
            print(f"ğŸ”§ Remediation Actions: {remediation_count}")
        
        print(f"\nğŸ‰ END-TO-END TEST COMPLETED SUCCESSFULLY!")
        print("All agents have processed real data and generated outputs")
        
    else:
        print("âŒ Test failed - no metrics uploaded")

if __name__ == "__main__":
    run_comprehensive_test()